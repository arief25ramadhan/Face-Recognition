{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Python for Face Recognition and Identification\n",
    "\n",
    "Use python and opencv Haar Cascade face detector and LBPH face recognizer to build a face recognition system.\n",
    "\n",
    "\n",
    "## Source:\n",
    "https://www.youtube.com/watch?v=PmZ29Vta7Vc&list=PLIxHGHeOyd0zy51wDjY0wjVpAjo3E93ir&index=29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use openCV Haarcascade model for face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python37\\site-packages\\cv2\\cv2.cp37-win_amd64.pyd\n"
     ]
    }
   ],
   "source": [
    "# Search your opencv location by running this print statement.\n",
    "# My opencv location is : C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python37\\site-packages\\cv2\n",
    "# Go to a folder named \"data\" and copy the 'haarcascade_frontalface_alt2.xml' to your folder\n",
    "print(cv2.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import opencv buildin cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier('cascades/haarcascade_frontalface_alt2.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing web cam. Press q to quit the camera\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, minNeighbors = 5) #scaleFactor\n",
    "    \n",
    "    # x,y = start of the faces frame(top left)\n",
    "    # w,h = width and height of frame\n",
    "    for (x, y, w, h) in faces:\n",
    "\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        #img_item = 'my_image.png'\n",
    "        #cv2.imwrite(img_item, roi_gray)\n",
    "        \n",
    "        # Draw a rectangle around detected faces\n",
    "        color = (255, 0, 0) #BGR (opencv default)\n",
    "        stroke = 2 #line thickness\n",
    "        end_cord_x = x+w\n",
    "        end_cord_y = y+h\n",
    "        cv2.rectangle(frame, (x,y), (end_cord_x, end_cord_y), color, stroke)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    # Press q to quit/turn off camera\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arief_ramadhan C:/Users/ACER/Desktop/learn_arief/opencv/face_image/arief_ramadhan\\arief_ramadhan_1.jpg\n",
      "{'arief_ramadhan': 0}\n",
      "arief_ramadhan C:/Users/ACER/Desktop/learn_arief/opencv/face_image/arief_ramadhan\\arief_ramadhan_2.png\n",
      "{'arief_ramadhan': 0}\n",
      "arief_ramadhan C:/Users/ACER/Desktop/learn_arief/opencv/face_image/arief_ramadhan\\arief_ramadhan_3.jpg\n",
      "{'arief_ramadhan': 0}\n",
      "arief_ramadhan C:/Users/ACER/Desktop/learn_arief/opencv/face_image/arief_ramadhan\\arief_ramadhan_4.jpg\n",
      "{'arief_ramadhan': 0}\n",
      "arief_ramadhan C:/Users/ACER/Desktop/learn_arief/opencv/face_image/arief_ramadhan\\arief_ramadhan_5.jpg\n",
      "{'arief_ramadhan': 0}\n",
      "bill_gates C:/Users/ACER/Desktop/learn_arief/opencv/face_image/bill_gates\\bill_gates_1.jpg\n",
      "{'arief_ramadhan': 0, 'bill_gates': 1}\n",
      "bill_gates C:/Users/ACER/Desktop/learn_arief/opencv/face_image/bill_gates\\bill_gates_2.jpg\n",
      "{'arief_ramadhan': 0, 'bill_gates': 1}\n",
      "bill_gates C:/Users/ACER/Desktop/learn_arief/opencv/face_image/bill_gates\\bill_gates_3.jpg\n",
      "{'arief_ramadhan': 0, 'bill_gates': 1}\n",
      "bill_gates C:/Users/ACER/Desktop/learn_arief/opencv/face_image/bill_gates\\bill_gates_4.jpg\n",
      "{'arief_ramadhan': 0, 'bill_gates': 1}\n",
      "bill_gates C:/Users/ACER/Desktop/learn_arief/opencv/face_image/bill_gates\\bill_gates_5.jpg\n",
      "{'arief_ramadhan': 0, 'bill_gates': 1}\n",
      "steve_wozniak C:/Users/ACER/Desktop/learn_arief/opencv/face_image/steve_wozniak\\steve_wozniak_1.jpg\n",
      "{'arief_ramadhan': 0, 'bill_gates': 1, 'steve_wozniak': 2}\n",
      "steve_wozniak C:/Users/ACER/Desktop/learn_arief/opencv/face_image/steve_wozniak\\steve_wozniak_2.jpg\n",
      "{'arief_ramadhan': 0, 'bill_gates': 1, 'steve_wozniak': 2}\n",
      "steve_wozniak C:/Users/ACER/Desktop/learn_arief/opencv/face_image/steve_wozniak\\steve_wozniak_3.jpg\n",
      "{'arief_ramadhan': 0, 'bill_gates': 1, 'steve_wozniak': 2}\n",
      "steve_wozniak C:/Users/ACER/Desktop/learn_arief/opencv/face_image/steve_wozniak\\steve_wozniak_4.jpg\n",
      "{'arief_ramadhan': 0, 'bill_gates': 1, 'steve_wozniak': 2}\n",
      "steve_wozniak C:/Users/ACER/Desktop/learn_arief/opencv/face_image/steve_wozniak\\steve_wozniak_5.jpg\n",
      "{'arief_ramadhan': 0, 'bill_gates': 1, 'steve_wozniak': 2}\n",
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2]\n",
      "[array([[255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       ...,\n",
      "       [255, 255, 255, ...,  24,  19,  19],\n",
      "       [255, 255, 255, ...,  21,  20,  21],\n",
      "       [255, 255, 255, ...,  18,  20,  21]], dtype=uint8), array([[131, 139, 143, ..., 229, 229, 229],\n",
      "       [117, 126, 137, ..., 229, 229, 229],\n",
      "       [102, 109, 119, ..., 229, 229, 229],\n",
      "       ...,\n",
      "       [ 56,  55,  57, ..., 227, 227, 228],\n",
      "       [ 57,  56,  57, ..., 227, 227, 228],\n",
      "       [ 58,  57,  57, ..., 227, 227, 228]], dtype=uint8), array([[227, 228, 224, ..., 218, 220, 221],\n",
      "       [228, 229, 224, ..., 218, 221, 225],\n",
      "       [228, 228, 224, ..., 219, 223, 228],\n",
      "       ...,\n",
      "       [ 97,  99,  91, ...,  94, 101, 103],\n",
      "       [106, 102, 100, ...,  96, 102, 104],\n",
      "       [112, 102, 103, ...,  98, 104, 104]], dtype=uint8), array([[130, 134, 138, ..., 237, 228, 183],\n",
      "       [132, 137, 138, ..., 213, 241, 205],\n",
      "       [134, 139, 138, ..., 191, 234, 228],\n",
      "       ...,\n",
      "       [ 55,  47,  78, ..., 138,  83,  42],\n",
      "       [ 55,  46,  78, ..., 199, 214, 133],\n",
      "       [ 55,  46,  79, ...,  96, 205, 235]], dtype=uint8), array([[57, 57, 53, ..., 60, 61, 62],\n",
      "       [58, 58, 52, ..., 68, 69, 69],\n",
      "       [56, 56, 51, ..., 73, 73, 74],\n",
      "       ...,\n",
      "       [50, 49, 18, ..., 86, 86, 86],\n",
      "       [52, 51, 31, ..., 80, 78, 76],\n",
      "       [54, 53, 40, ..., 81, 80, 79]], dtype=uint8), array([[184, 186, 187, ..., 194, 193, 193],\n",
      "       [184, 185, 188, ..., 194, 194, 193],\n",
      "       [183, 184, 187, ..., 194, 194, 193],\n",
      "       ...,\n",
      "       [184, 185, 186, ..., 194, 194, 194],\n",
      "       [183, 184, 185, ..., 192, 192, 193],\n",
      "       [183, 183, 184, ..., 190, 190, 191]], dtype=uint8), array([[232, 233, 231, ..., 162, 160, 158],\n",
      "       [232, 232, 230, ..., 163, 161, 160],\n",
      "       [230, 230, 229, ..., 161, 161, 160],\n",
      "       ...,\n",
      "       [ 82,  79,  68, ...,  75,  78,  79],\n",
      "       [ 75,  68,  73, ...,  67,  70,  75],\n",
      "       [ 72,  68,  79, ...,  65,  66,  71]], dtype=uint8), array([[ 31,  31,  31, ..., 159, 160, 160],\n",
      "       [ 31,  31,  31, ..., 159, 160, 160],\n",
      "       [ 31,  31,  31, ..., 159, 160, 160],\n",
      "       ...,\n",
      "       [ 31,  31,  31, ..., 190, 190, 190],\n",
      "       [ 31,  31,  31, ..., 190, 190, 190],\n",
      "       [ 31,  31,  31, ..., 191, 191, 191]], dtype=uint8), array([[ 82,  83,  88, ..., 159, 154, 149],\n",
      "       [ 84,  86,  89, ..., 159, 157, 156],\n",
      "       [ 87,  88,  88, ..., 160, 161, 163],\n",
      "       ...,\n",
      "       [163, 166, 160, ..., 194, 192, 190],\n",
      "       [163, 164, 158, ..., 191, 190, 189],\n",
      "       [164, 162, 155, ..., 186, 186, 186]], dtype=uint8), array([[ 89,  89,  88, ..., 122, 124, 125],\n",
      "       [ 89,  89,  89, ..., 123, 125, 124],\n",
      "       [ 89,  89,  89, ..., 124, 123, 121],\n",
      "       ...,\n",
      "       [195, 194, 195, ...,  93,  93, 102],\n",
      "       [192, 193, 189, ...,  75,  73,  55],\n",
      "       [195, 196, 196, ...,  56,  33,  37]], dtype=uint8), array([[143, 144, 150, ...,   9,   7,   5],\n",
      "       [146, 146, 139, ...,   9,   9,   8],\n",
      "       [148, 148, 141, ...,   8,   8,   8],\n",
      "       ...,\n",
      "       [ 44,  50, 108, ...,  44,  24,  49],\n",
      "       [ 68,  82, 153, ...,  40,  35,  42],\n",
      "       [146, 148,  88, ...,  38,  47,  37]], dtype=uint8), array([[143, 144, 144, ..., 110, 117, 124],\n",
      "       [144, 144, 144, ..., 114, 122, 129],\n",
      "       [144, 144, 144, ..., 112, 119, 125],\n",
      "       ...,\n",
      "       [145, 145, 144, ..., 123, 127, 131],\n",
      "       [145, 145, 144, ..., 126, 128, 131],\n",
      "       [145, 145, 145, ..., 130, 130, 131]], dtype=uint8), array([[ 16,  18,  21, ..., 149, 154, 150],\n",
      "       [ 21,  23,  26, ..., 140, 145, 148],\n",
      "       [ 26,  28,  30, ..., 128, 131, 138],\n",
      "       ...,\n",
      "       [ 25,  25,  23, ...,  27,  27,  26],\n",
      "       [ 24,  25,  23, ...,  27,  27,  26],\n",
      "       [ 24,  25,  23, ...,  27,  27,  26]], dtype=uint8), array([[83, 83, 85, ..., 89, 88, 84],\n",
      "       [84, 83, 84, ..., 88, 87, 86],\n",
      "       [82, 83, 80, ..., 84, 85, 87],\n",
      "       ...,\n",
      "       [94, 94, 92, ..., 98, 99, 99],\n",
      "       [94, 94, 93, ..., 98, 98, 98],\n",
      "       [95, 94, 95, ..., 96, 97, 97]], dtype=uint8), array([[143, 139, 142, ...,  58,  57,  57],\n",
      "       [141, 140, 139, ...,  58,  57,  57],\n",
      "       [135, 138, 135, ...,  57,  56,  56],\n",
      "       ...,\n",
      "       [ 67,  63,  96, ...,  10,   9,  10],\n",
      "       [ 96, 101,  80, ...,  10,  10,  10],\n",
      "       [108, 102,  62, ...,  12,  11,  10]], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "# Define image directory\n",
    "image_dir = 'C:/Users/ACER/Desktop/learn_arief/opencv/face_image/'\n",
    "\n",
    "# Initialize training set and labels\n",
    "x_train = []\n",
    "y_labels = []\n",
    "\n",
    "# Create a dictionary to convert labels into numeric\n",
    "current_id = 0\n",
    "label_ids ={}\n",
    "\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('png') or file.endswith('jpg') or file.endswith('jpeg'):\n",
    "            path = os.path.join(root, file)\n",
    "            label = os.path.basename(root) #os.path.dirname(path)\n",
    "            #path = path.replace('\\\\', '/')\n",
    "            print(label, path)\n",
    "            \n",
    "            if not label in label_ids:\n",
    "                label_ids[label] = current_id\n",
    "                current_id += 1\n",
    "            id_ = label_ids[label]\n",
    "            print(label_ids)\n",
    "            \n",
    "            pil_image = Image.open(path).convert('L')\n",
    "            ## Rezise image (if necessary)\n",
    "            # size = (550, 550)\n",
    "            # final_image = pil_image.resize(size, Image.ANTIALIAS)            \n",
    "            image_array = np.array(pil_image, 'uint8') #change pil_image to final_image if you resize the image\n",
    "            faces = face_cascade.detectMultiScale(gray, minNeighbors = 5)\n",
    "                    \n",
    "            # Detect faces in the image\n",
    "            for (x,y,w,h) in faces:\n",
    "                roi = image_array[y:y+h, x:x+w]\n",
    "                x_train.append(roi)\n",
    "                y_labels.append(id_)\n",
    "\n",
    "print(y_labels)                \n",
    "print(x_train)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data label to a pickle file\n",
    "\n",
    "with open('labels.pickle', 'wb') as f:\n",
    "    pickle.dump(label_ids, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use open CV face recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import open cv recognizer\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train recognizer on the images\n",
    "recognizer.train(x_train, np.array(y_labels))\n",
    "\n",
    "# Save the trained recognizer\n",
    "recognizer.save('trainer.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Combine the face detector (Haar Cascade) and the Face Recognizer (LBPH) into one function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import face detector and face recognizer\n",
    "face_cascade = cv2.CascadeClassifier('cascades/haarcascade_frontalface_alt2.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('trainer.yml')\n",
    "\n",
    "# Optional: use Haar Cascade for eyes. Get it from the same folder where you find the haarcascade_frontalface_alt2.xml\n",
    "eye_cascade = cv2.CascadeClassifier('cascades/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arief_ramadhan bill_gates steve_wozniak\n"
     ]
    }
   ],
   "source": [
    "# Inverse label\n",
    "label = {v:k for k,v in label_ids.items()}\n",
    "print(label[0], label[1], label[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n",
      "0\n",
      "arief_ramadhan\n"
     ]
    }
   ],
   "source": [
    "# Accessing web cam. Press q to quit the camera\n",
    "\n",
    "## Initialize web cam \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, minNeighbors = 5)\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        id_, conf = recognizer.predict(roi_gray)\n",
    "        \n",
    "        img_item = 'my_image.png'\n",
    "        cv2.imwrite(img_item, roi_gray)\n",
    "        \n",
    "        if conf >= 45:\n",
    "            print(id_)\n",
    "            print(label[id_])\n",
    "            \n",
    "            # Draw labels on the Haar Cascade rectangle\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            name = label[id_]\n",
    "            color = (255, 255, 255)\n",
    "            stroke = 2\n",
    "            cv2.putText(frame, name, (x,y), font, 1, color, stroke, cv2.LINE_AA)\n",
    "        \n",
    "        # Draw a rectangle around detected faces\n",
    "        color = (255, 0, 0) #BGR (opencv default)\n",
    "        stroke = 2 #line thickness\n",
    "        end_cord_x = x+w\n",
    "        end_cord_y = y+h\n",
    "        cv2.rectangle(frame, (x,y), (end_cord_x, end_cord_y), color, stroke)\n",
    "        \n",
    "        ## Optional: create rectangles for eyes\n",
    "#         eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "#         for (ex, ey, ew, eh) in eyes:\n",
    "#             cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0,255,0), 2)\n",
    "            \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    # Press q to quit/turn off camera\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
